import streamlit as st
from PIL import Image, ImageStat, ImageFilter
import io
import random
import colorsys
import os
import base64
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Optional import for Google Gemini
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

def generate_caption_with_gemini(image_bytes, prompt=None):
    """
    Generate a caption for an image using Google's Gemini multimodal model.
    
    Args:
        image_bytes: The binary image data
        prompt: Custom prompt to guide the caption generation
        
    Returns:
        str: A caption for the image generated by Gemini
    """
    try:
        # Check if the API key is available
        api_key = os.getenv("GOOGLE_GEMINI_API_KEY")
        # Print debug info to console (not visible to user)
        print(f"API Key exists: {bool(api_key)}, Value: {api_key[:5]}..." if api_key else "API Key not found")
        if not api_key:
            return "‚ö†Ô∏è Gemini API key not configured. Please add your API key to the .env file."
        
        # Configure the Gemini API client
        genai.configure(api_key=api_key)
        
        # Get the Gemini model that supports vision
        # Try the newer model names first, then fall back to older ones
        try:
            # Directly use the Gemini 1.5 Flash model which we know works with images
            # and doesn't trigger quota limits as easily
            model = genai.GenerativeModel('gemini-1.5-flash')
            st.info("Using Gemini 1.5 Flash model - compatible with image processing")
        except Exception as model_error:
            st.warning(f"Error finding vision models: {str(model_error)}")
            # Fall back to latest Gemini model
            model = genai.GenerativeModel('gemini-1.5-flash')
            st.info("Using fallback model: gemini-1.5-flash")
        
        # Default prompt if none provided
        if not prompt:
            prompt = "Generate a detailed, creative caption for this image that would work well on social media."
        
        # Convert image bytes to mime-encoded format for the API
        mime_type = "image/jpeg"  # Default, but we could detect this from the image
        image_parts = [
            {
                "inline_data": {
                    "mime_type": mime_type,
                    "data": base64.b64encode(image_bytes).decode("utf-8")
                }
            }
        ]
        
        try:
            # Generate the caption
            generation_config = {
                "temperature": 0.7,
                "top_p": 1,
                "top_k": 32,
                "max_output_tokens": 1024,
            }
            
            safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
            ]
            
            response = model.generate_content(
                contents=[prompt, *image_parts],
                generation_config=generation_config,
                safety_settings=safety_settings,
            )
            
            # Extract and return the caption
            if hasattr(response, 'text'):
                return response.text.strip()
            elif hasattr(response, 'parts'):
                return ''.join(part.text for part in response.parts)
            else:
                return str(response)
                
        except Exception as gen_error:
            st.error(f"Error during content generation: {str(gen_error)}")
            return f"Unable to generate caption with the current model. Error: {str(gen_error)}"
    
    except Exception as e:
        error_message = f"Error generating caption with Gemini: {str(e)}"
        # Print detailed error for debugging
        print(f"DETAILED ERROR: {type(e).__name__}: {e}")
        st.error(error_message)
        return f"Unable to generate caption with Gemini. Error: {str(e)}"

def generate_caption(image_bytes, caption_source="local", custom_prompt=None):
    """
    Generate a caption for an image using either local analysis or Gemini.
    
    Args:
        image_bytes: The binary image data
        caption_source: "local" for offline processing, "gemini" for AI-generated captions
        custom_prompt: Custom prompt for Gemini (ignored for local captions)
        
    Returns:
        str: A descriptive caption for the image
    """
    # If Gemini is selected and available, use it
    if caption_source == "gemini":
        if GEMINI_AVAILABLE:
            return generate_caption_with_gemini(image_bytes, custom_prompt)
        else:
            st.warning("Google Generative AI package not installed. Run 'pip install google-generativeai'")
            st.info("Falling back to local caption generation.")
    
    # Local caption generation
    try:
        # Open the image
        img = Image.open(io.BytesIO(image_bytes))
        
        # Extract basic properties
        width, height = img.size
        format_name = img.format if img.format else "image"
        aspect = "portrait" if height > width else "landscape" if width > height else "square"
        
        # Check if image is color or black and white
        is_color = img.mode in ("RGB", "RGBA", "CMYK")
        
        # Analyze colors if it's a color image
        color_description = ""
        if is_color:
            # Convert to RGB if not already
            if img.mode != "RGB":
                img = img.convert("RGB")
                
            # Resize for faster processing
            img_small = img.resize((100, 100))
            
            # Get color statistics
            stat = ImageStat.Stat(img_small)
            r, g, b = stat.mean
            
            # Calculate brightness
            brightness = (0.299 * r + 0.587 * g + 0.114 * b) / 255
            
            # Determine dominant colors
            img_small = img_small.quantize(colors=5)
            palette = img_small.getpalette()
            color_counts = img_small.getcolors()
            dominant_colors = []
            
            if palette and color_counts:
                # Sort colors by frequency
                color_counts.sort(reverse=True)
                
                # Get top colors
                for count, color_index in color_counts[:3]:
                    r, g, b = palette[color_index*3:color_index*3+3]
                    
                    # Convert RGB to HSV for better color naming
                    h, s, v = colorsys.rgb_to_hsv(r/255, g/255, b/255)
                    
                    # Simple color naming
                    if s < 0.1:
                        if v < 0.3: color_name = "black"
                        elif v > 0.8: color_name = "white"
                        else: color_name = "gray"
                    elif h < 0.05 or h > 0.95: color_name = "red"
                    elif 0.05 <= h < 0.15: color_name = "orange"
                    elif 0.15 <= h < 0.22: color_name = "yellow"
                    elif 0.22 <= h < 0.41: color_name = "green"
                    elif 0.41 <= h < 0.55: color_name = "teal"
                    elif 0.55 <= h < 0.75: color_name = "blue"
                    elif 0.75 <= h < 0.82: color_name = "purple"
                    else: color_name = "pink"
                    
                    # Add intensity
                    if color_name not in ["black", "white", "gray"]:
                        if s < 0.4: color_name = f"pale {color_name}"
                        elif s > 0.8: color_name = f"vibrant {color_name}"
                        
                    dominant_colors.append(color_name)
                
                # Remove duplicates
                dominant_colors = list(dict.fromkeys(dominant_colors))
                
                # Format color description
                if len(dominant_colors) == 1:
                    color_description = f"with {dominant_colors[0]} tones"
                elif len(dominant_colors) == 2:
                    color_description = f"with {dominant_colors[0]} and {dominant_colors[1]} tones"
                else:
                    color_description = f"with {', '.join(dominant_colors[:-1])} and {dominant_colors[-1]} tones"
            
            # Add brightness description
            if brightness < 0.3:
                tone = "dark"
            elif brightness > 0.7:
                tone = "bright"
            else:
                tone = "balanced"
            
            color_description = f"{tone} {color_description}"
        else:
            color_description = "in black and white"
        
        # Detect edges to estimate complexity
        edge_img = img.convert("L").filter(ImageFilter.FIND_EDGES)
        edge_stat = ImageStat.Stat(edge_img)
        edge_mean = edge_stat.mean[0]
        
        if edge_mean < 20:
            complexity = "simple, minimalist"
        elif edge_mean > 50:
            complexity = "detailed, complex"
        else:
            complexity = "well-composed"
        
        # Try to detect content type using simple heuristics
        content_type = ""
        
        if width / height > 2 or height / width > 2:
            content_type = "panoramic scene"
        elif aspect == "landscape" and brightness > 0.6:
            content_descriptions = [
                "outdoor scene", "landscape photograph", "scenic view",
                "natural setting", "environmental photograph"
            ]
            content_type = random.choice(content_descriptions)
        elif aspect == "portrait" and edge_mean > 30:
            content_type = "portrait or close-up photograph"
        elif edge_mean < 15 and brightness > 0.8:
            content_type = "minimalist composition"
        elif edge_mean > 60:
            content_descriptions = [
                "detailed photograph", "intricate scene", "richly detailed image",
                "complex composition", "detailed artwork"
            ]
            content_type = random.choice(content_descriptions)
        else:
            content_descriptions = [
                "photograph", "image", "composition", "visual", "picture"
            ]
            content_type = random.choice(content_descriptions)
        
        # Generate caption
        descriptors = [
            "striking", "captivating", "interesting", "compelling", "eye-catching",
            "engaging", "remarkable", "notable", "impressive", "intriguing"
        ]
        descriptor = random.choice(descriptors)
        
        caption = f"A {descriptor} {aspect} {content_type} {color_description}. This {complexity} image exhibits careful composition and visual balance."
        
        return caption
    
    except Exception as e:
        # Handle any errors gracefully
        st.error(f"Error generating caption: {str(e)}")
        
        # If even the local generation fails, return a generic message
        return "An image was uploaded. (An error occurred during caption generation.)"

def main():
    # Set page config
    st.set_page_config(page_title="Safe Caption Web", page_icon="üñºÔ∏è", layout="centered")
    
    # Apply CSS for dark theme
    st.markdown("""
        <style>
        .main {
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #ffffff;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # Main content
    st.title("üñºÔ∏è Image Caption Generator")
    
    # Caption source selector
    caption_source = st.radio(
        "Caption Source",
        ["Local (Offline)", "Gemini AI (Online)"],
        index=0,
        format_func=lambda x: x,
        horizontal=True
    )
    
    # Convert friendly names to internal values
    caption_source_value = "local" if caption_source == "Local (Offline)" else "gemini"
    
    # Custom prompt for Gemini (only shown when Gemini is selected)
    custom_prompt = None
    if caption_source_value == "gemini":
        with st.expander("Customize Prompt (Optional)", expanded=False):
            custom_prompt = st.text_area(
                "Prompt for Gemini",
                value="Generate a detailed, creative caption for this image that would work well on social media.",
                height=100
            )
            st.info("Customize how Gemini describes your image. Try prompts like 'Describe this image like a movie scene' or 'Write a poetic caption for this landscape'.")
    
    # File uploader
    uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"], accept_multiple_files=False)
    
    if uploaded_file is not None:
        # Process the uploaded image
        image_bytes = uploaded_file.read()
        image = Image.open(io.BytesIO(image_bytes))
        
        # Display the image
        st.image(image, caption="", use_container_width=True)
        
        # Add a progress bar for better visual feedback
        progress_bar = st.progress(0)
        for i in range(100):
            # Update progress bar
            progress_bar.progress(i + 1)
            
        # Generate caption with spinner
        with st.spinner(f"Generating your caption using {caption_source}..."):
            caption = generate_caption(image_bytes, caption_source=caption_source_value, custom_prompt=custom_prompt)
        
        # Display the caption
        st.subheader("Generated Caption:")
        st.info(caption)
        
        # Add source attribution if using Gemini
        if caption_source_value == "gemini":
            st.caption("Caption generated using Google's Gemini AI")
        else:
            st.caption("Caption generated locally using image analysis")
        
        # Memory cleanup for privacy
        del image_bytes
        del image
        del caption
    else:
        # Show instructions when no image is uploaded
        st.info("Please upload an image to get started.")
        st.caption("This application can generate image captions in two ways:")
        st.markdown("- **Local**: Works completely offline with basic image analysis")
        st.markdown("- **Gemini**: Uses Google's AI for detailed, creative captions (requires API key)")
    
    # Footer with markdown instead of HTML
    st.markdown("---")
    st.caption("Safe Caption Web - Your privacy-focused image captioning solution")
    st.caption("Developed with ‚ô• | Images processed securely | Never stored")

if __name__ == "__main__":
    main()
